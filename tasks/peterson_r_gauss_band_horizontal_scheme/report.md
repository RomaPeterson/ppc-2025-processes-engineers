# Метод Гаусса – ленточная горизонтальная схема

- Студент: Петерсон Роман Дмитриевич, группа 3823Б1ПР5  
- Технология: MPI, SEQ  
- Вариант: 15  

## 1. Введение
Метод Гаусса является фундаментальным алгоритмом решения систем линейных уравнений (СЛАУ). Для ленточных матриц с ограниченной шириной ленты можно применять специализированные схемы вычислений, которые значительно повышают производительность. Данный проект реализует последовательную и MPI-параллельную версии метода Гаусса с горизонтальным распределением данных для ленточных матриц, что позволяет эффективно решать большие системы уравнений.

## 2. Постановка задачи
Решить систему n линейных уравнений с n неизвестными: Ax = b, где A — ленточная матрица с шириной ленты w (элементы aᵢⱼ = 0 при |i-j| > w).

**Формат входных данных:** Расширенная матрица (n строк × (n+1) столбцов), где первые n столбцов представляют матрицу A, а последний столбец — вектор b.  
**Формат выходных данных:** Вектор решения x длины n.  
**Ограничения:** Матрица должна быть квадратной (n×n), расширенная матрица должна иметь n+1 столбцов, для устойчивости рекомендуется диагональное преобладание.

## 3. Базовый алгоритм (последовательный)
1. Прямой ход (триангуляция):
   - Для каждого ведущего элемента k (0 ≤ k < n):
     - Выбор ведущей строки с максимальным |aₖₖ| (частичный выбор)
     - Нормализация ведущей строки
     - Исключение нижележащих строк: для i = k+1 до n-1: строкаᵢ ← строкаᵢ - множитель × строкаₖ
2. Обратный ход:
   - Для i = n-1 до 0:
     - xᵢ = (bᵢ - Σ aᵢⱼ×xⱼ) / aᵢᵢ

**Сложность:** O(n³) для плотных матриц, O(n×w²) для ленточных матриц.  
**Память:** O(n×(n+1)) для плотного хранения.

## 4. Схема распараллеливания (MPI)
**Распределение данных (горизонтальная схема):** Строки распределяются циклически между процессами. Строка i назначается процессу (i % size).

**Коммуникационная схема:**
1. Во время прямого хода для ведущей строки k:
   - Процесс, владеющий строкой k, рассылает её всем процессам
   - Каждый процесс исключает ведущую строку из своих локальных строк
2. Во время обратного хода:
   - Процесс, владеющий строкой i, вычисляет xᵢ и рассылает его
   - Все процессы обновляют свои вычисления

**Роли процессов:** Все процессы выполняют исключение на своих локальных строках. Процесс, владеющий текущей ведущей строкой, выступает источником рассылки.

**Псевдокод (MPI):**
```
// Прямой ход
for k = 0 до n-1:
    владелец = k % size
    if ранг == владелец:
        ведущая_строка = локальная_строка(k)
    MPI_Bcast(ведущая_строка, владелец)
    для каждой локальной строки i > k:
        исключить с использованием ведущей_строки

// Обратный ход
for i = n-1 до 0:
    владелец = i % size
    if ранг == владелец:
        x[i] = вычислить из локальной строки i
    MPI_Bcast(x[i], владелец)
```

## 5. Детали реализации
**Структура кода:**
- `ops_seq.hpp/cpp` – Последовательный метод Гаусса с частичным выбором
- `ops_mpi.hpp/cpp` – MPI-параллельная версия с горизонтальным распределением строк
- `common.hpp` – Определения типов (InType = vector<vector<double>>)
- `main.cpp` – Функциональные и производительные тесты

**Ключевые классы:**
- `PetersonRGaussBandHorizontalSchemeSEQ` – Последовательная реализация
- `PetersonRGaussBandHorizontalSchemeMPI` – MPI-параллельная реализация

**Важные особенности:**
- Частичный выбор ведущего элемента для численной устойчивости
- Оптимизация для ленточных матриц при генерации (хотя хранение плотное)
- Циклическое распределение строк для балансировки нагрузки
- Валидация размеров и структуры матрицы

**Использование памяти:**
- Каждый процесс хранит только назначенные ему строки
- Поддерживается отображение глобальных индексов на локальные
- Используется плотное хранение (может быть оптимизировано для ленточной структуры)

## 6. Экспериментальная установка
**Аппаратное обеспечение:**
- Процессор: Intel Core i5-9400F (6 ядер, 6 потоков) @ 2.90 ГГц
- ОЗУ: 16 ГБ DDR4
- ОС: Ubuntu 20.04.4 LTS

**Программное обеспечение:**
- Компилятор: GCC 9.4.0
- Тип сборки: RelWithDebInfo (оптимизация -O3)
- MPI: OpenMPI 4.0.3
- Тестирование: GoogleTest 1.11.0

**Параметры запуска:**
- MPI-процессы: 1–6 (через `mpirun -np N`)
- Размер матрицы в perf-тестах: 1000×1000 с шириной ленты 5
- Тестовые матрицы: с диагональным преобладанием для устойчивости

**Генерация данных:** В perf-тестах генерируются ленточные матрицы с заданным размером и шириной ленты, гарантируется диагональное преобладание.

## 7. Результаты и обсуждение

### 7.1 Корректность
Проверка корректности выполнена:
- Юнит-тестами на некорректные входные данные (пустая матрица, несоответствие размеров)
- Функциональными тестами с известными решениями (построены так, чтобы x = [1,2,3,...])
- Вычислением невязки: ||Ax - b|| < ε (ε = 1e-5)
- Сравнением результатов SEQ и MPI на нескольких тестовых случаях

### 7.2 Производительность
Результаты для ленточной матрицы 1000×1000 (ширина ленты=5):

| Режим | Процессы | Время, с | Ускорение | Эффективность |
|-------|----------|----------|-----------|---------------|
| SEQ   | 1        | 2.14     | 1.00      | –             |
| MPI   | 2        | 1.18     | 1.81      | 90.5%         |
| MPI   | 4        | 0.67     | 3.19      | 79.8%         |
| MPI   | 6        | 0.49     | 4.37      | 72.8%         |

**Анализ:**
- Хорошее ускорение (4.37× на 6 процессах) для ленточной матрицы
- Эффективность снижается с увеличением числа процессов из-за:
  - Роста коммуникационных накладных расходов (рассылка ведущих строк)
  - Дисбаланса нагрузки при циклическом распределении
  - Последовательной фазы обратного хода
- Ограниченная ширина ленты уменьшает вычисления на строку, делая коммуникации более значимыми

**Ограничения масштабируемости:**
- Накладные расходы на коммуникацию растут с количеством ведущих строк (n рассылок)
- Ограничены шириной ленты: более узкие ленты уменьшают вычисления, но не коммуникации
- Наиболее эффективны при n ≫ числа процессов

## 8. Выводы
1. Реализованный метод Гаусса с горизонтальным распределением строк корректно работает для ленточных матриц.
2. Достигнуто ускорение 4.37× на 6 процессах с хорошей эффективностью (73%).
3. Горизонтальная схема эффективна для балансировки нагрузки, но создает коммуникационные накладные расходы.
4. Текущая реализация использует плотное хранение; может быть оптимизирована для ленточной структуры.
5. Алгоритм устойчив с частичным выбором и подходит для систем с диагональным преобладанием.

**Ограничения и улучшения:**
- Плотное хранение неэффективно для очень больших матриц
- Коммуникации могут быть совмещены с вычислениями
- Конвейеризация может уменьшить зависимости при рассылке

## 9. Литература

1. Документация по курсу: "Параллельное программирование": https://learning-process.github.io/parallel_programming_course/ru/index.html (Оболенский А.А, Нестеров А.Ю)
2. Лекции по курсу "Параллельное программирование". (Сысоев А.В. ННГУ 2025 г.)
3. Документация по MPI: https://www.open-mpi.org/